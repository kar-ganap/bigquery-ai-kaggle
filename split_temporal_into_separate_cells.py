#!/usr/bin/env python3
"""
Split temporal analysis into separate cells for better notebook organization
"""

import json

# Load the notebook
notebook_path = "/Users/kartikganapathi/Documents/Personal/random_projects/bigquery_ai_kaggle/us-ads-strategy-radar/notebooks/demo_competitive_intelligence.ipynb"

with open(notebook_path, 'r') as f:
    notebook = json.load(f)

# Find the cell with temporal analysis and split it
for i, cell in enumerate(notebook['cells']):
    if cell['cell_type'] == 'code' and 'source' in cell:
        source_text = ''.join(cell['source'])

        # Find the cell with temporal analysis
        if "TEMPORAL INTELLIGENCE WITH CONFIDENCE" in source_text:
            print(f"Found temporal analysis in cell #{i} - splitting into separate cells...")

            # Extract the original cell content (everything before temporal analysis)
            lines = cell['source']
            split_index = -1

            for j, line in enumerate(lines):
                if "TEMPORAL INTELLIGENCE WITH CONFIDENCE" in line:
                    split_index = j
                    break

            if split_index > 0:
                # Keep original content in current cell
                cell['source'] = lines[:split_index]

                # Create markdown cell for temporal analysis introduction
                temporal_intro_cell = {
                    "cell_type": "markdown",
                    "metadata": {},
                    "source": [
                        "## ⏰ **TEMPORAL INTELLIGENCE & FORECASTING**\n",
                        "\n",
                        "**Advanced temporal analysis with statistical confidence intervals**\n",
                        "\n",
                        "### 📊 **Analysis Modules:**\n",
                        "- **🎨 Creative Fatigue Forecasting**: 4-week predictions with 95% confidence intervals\n",
                        "- **📈 Market Momentum Analysis**: Velocity trends with uncertainty bands  \n",
                        "- **🔄 Competitive Copying Intelligence**: Threat escalation with probability ranges\n",
                        "\n",
                        "### 🎯 **Statistical Features:**\n",
                        "- Proper confidence intervals that widen over forecast horizon\n",
                        "- Uncertainty quantification for business decision-making\n",
                        "- Risk assessments with probability statements\n",
                        "\n",
                        "---"
                    ]
                }

                # Create Creative Fatigue Analysis cell
                creative_fatigue_cell = {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# === 🎨 CREATIVE FATIGUE FORECASTING WITH CONFIDENCE INTERVALS ===\n",
                        "\n",
                        "print(\"🎨 CREATIVE FATIGUE FORECAST (with 95% confidence intervals)\")\n",
                        "print(\"=\" * 70)\n",
                        "\n",
                        "try:\n",
                        "    from src.utils.bigquery_client import run_query\n",
                        "    import os\n",
                        "    import numpy as np\n",
                        "    \n",
                        "    BQ_PROJECT = os.environ.get(\"BQ_PROJECT\", \"bigquery-ai-kaggle-469620\")\n",
                        "    BQ_DATASET = os.environ.get(\"BQ_DATASET\", \"ads_demo\")\n",
                        "\n",
                        "    # Query creative fatigue data\n",
                        "    fatigue_query = f\"\"\"\n",
                        "    SELECT\n",
                        "        brand,\n",
                        "        EXTRACT(WEEK FROM ad_creation_date) as week_number,\n",
                        "        AVG(CAST(brand_consistency AS FLOAT64)) as avg_brand_consistency,\n",
                        "        STDDEV(CAST(brand_consistency AS FLOAT64)) as std_brand_consistency,\n",
                        "        AVG(CAST(creative_fatigue_risk AS FLOAT64)) as avg_fatigue_risk,\n",
                        "        STDDEV(CAST(creative_fatigue_risk AS FLOAT64)) as std_fatigue_risk,\n",
                        "        COUNT(*) as ad_count\n",
                        "    FROM `{BQ_PROJECT}.{BQ_DATASET}.ads_with_dates`\n",
                        "    WHERE ad_creation_date IS NOT NULL\n",
                        "    AND brand_consistency IS NOT NULL\n",
                        "    GROUP BY brand, week_number\n",
                        "    HAVING ad_count >= 2\n",
                        "    ORDER BY week_number, brand\n",
                        "    \"\"\"\n",
                        "\n",
                        "    fatigue_df = run_query(fatigue_query)\n",
                        "\n",
                        "    if not fatigue_df.empty:\n",
                        "        print(\"📊 Creative Fatigue Analysis by Brand:\")\n",
                        "        print()\n",
                        "\n",
                        "        for brand in fatigue_df['brand'].unique():\n",
                        "            brand_data = fatigue_df[fatigue_df['brand'] == brand].sort_values('week_number')\n",
                        "\n",
                        "            if len(brand_data) >= 3:\n",
                        "                # Calculate trends and confidence intervals\n",
                        "                fatigue_values = brand_data['avg_fatigue_risk'].values\n",
                        "                weeks = range(len(fatigue_values))\n",
                        "\n",
                        "                # Linear trend analysis\n",
                        "                if len(fatigue_values) > 1:\n",
                        "                    trend_slope = np.polyfit(weeks, fatigue_values, 1)[0]\n",
                        "                    data_variance = np.var(fatigue_values)\n",
                        "                    prediction_std = np.sqrt(data_variance + (trend_slope ** 2))\n",
                        "                    current_fatigue = fatigue_values[-1]\n",
                        "\n",
                        "                    print(f\"🎨 {brand} - Creative Fatigue Analysis:\")\n",
                        "                    print(f\"   Current Risk: {current_fatigue:.3f}\")\n",
                        "                    print(f\"   Trend Slope: {trend_slope:+.4f}/week\")\n",
                        "                    print(f\"   Data Volatility: {prediction_std:.3f}\")\n",
                        "\n",
                        "                    # 4-week forecast with confidence intervals\n",
                        "                    print(\"\\n   📈 4-Week Forecast (95% Confidence Intervals):\")\n",
                        "                    for fw in [1, 2, 3, 4]:\n",
                        "                        predicted_fatigue = current_fatigue + (trend_slope * fw)\n",
                        "                        \n",
                        "                        # 95% confidence interval\n",
                        "                        confidence_margin = 1.96 * prediction_std * np.sqrt(fw)\n",
                        "                        lower_bound = max(0, predicted_fatigue - confidence_margin)\n",
                        "                        upper_bound = min(1, predicted_fatigue + confidence_margin)\n",
                        "                        confidence = max(0.3, 0.9 - (fw * 0.1))\n",
                        "\n",
                        "                        print(f\"      Week +{fw}: {predicted_fatigue:.3f} \"\n",
                        "                              f\"[{lower_bound:.3f}, {upper_bound:.3f}] \"\n",
                        "                              f\"(Confidence: {confidence:.0%})\")\n",
                        "\n",
                        "                        # Risk assessment\n",
                        "                        if lower_bound > 0.8:\n",
                        "                            print(f\"         🚨 HIGH RISK CONFIRMED - refresh needed (>95% confidence)\")\n",
                        "                        elif predicted_fatigue > 0.8:\n",
                        "                            print(f\"         ⚠️ HIGH RISK LIKELY - prepare refresh strategy\")\n",
                        "                        elif upper_bound > 0.8:\n",
                        "                            print(f\"         💡 POSSIBLE RISK - monitor for early signals\")\n",
                        "\n",
                        "                    print()\n",
                        "\n",
                        "    else:\n",
                        "        print(\"📊 Using estimated creative fatigue data for demonstration...\")\n",
                        "        \n",
                        "        # Simulated data for demo\n",
                        "        brands = ['Warby Parker', 'EyeBuyDirect', 'LensCrafters']\n",
                        "        \n",
                        "        for brand in brands:\n",
                        "            # Simulate different fatigue patterns\n",
                        "            if brand == 'Warby Parker':\n",
                        "                current_fatigue = 0.45\n",
                        "                trend_slope = 0.015  # Gradual increase\n",
                        "            elif brand == 'EyeBuyDirect':\n",
                        "                current_fatigue = 0.72\n",
                        "                trend_slope = 0.025  # Rapid increase\n",
                        "            else:\n",
                        "                current_fatigue = 0.38\n",
                        "                trend_slope = -0.005  # Improving\n",
                        "            \n",
                        "            prediction_std = 0.08\n",
                        "            \n",
                        "            print(f\"🎨 {brand} - Creative Fatigue Analysis:\")\n",
                        "            print(f\"   Current Risk: {current_fatigue:.3f}\")\n",
                        "            print(f\"   Trend Slope: {trend_slope:+.4f}/week\")\n",
                        "            \n",
                        "            print(\"\\n   📈 4-Week Forecast (95% Confidence Intervals):\")\n",
                        "            for fw in [1, 2, 3, 4]:\n",
                        "                predicted_fatigue = current_fatigue + (trend_slope * fw)\n",
                        "                \n",
                        "                confidence_margin = 1.96 * prediction_std * np.sqrt(fw)\n",
                        "                lower_bound = max(0, predicted_fatigue - confidence_margin)\n",
                        "                upper_bound = min(1, predicted_fatigue + confidence_margin)\n",
                        "                confidence = max(0.3, 0.9 - (fw * 0.1))\n",
                        "\n",
                        "                print(f\"      Week +{fw}: {predicted_fatigue:.3f} \"\n",
                        "                      f\"[{lower_bound:.3f}, {upper_bound:.3f}] \"\n",
                        "                      f\"(Confidence: {confidence:.0%})\")\n",
                        "\n",
                        "                # Risk assessment\n",
                        "                if lower_bound > 0.8:\n",
                        "                    print(f\"         🚨 HIGH RISK CONFIRMED - refresh needed (>95% confidence)\")\n",
                        "                elif predicted_fatigue > 0.8:\n",
                        "                    print(f\"         ⚠️ HIGH RISK LIKELY - prepare refresh strategy\")\n",
                        "                elif upper_bound > 0.8:\n",
                        "                    print(f\"         💡 POSSIBLE RISK - monitor for early signals\")\n",
                        "            print()\n",
                        "\n",
                        "except Exception as e:\n",
                        "    print(f\"❌ Creative fatigue analysis error: {str(e)}\")\n",
                        "    import traceback\n",
                        "    traceback.print_exc()"
                    ]
                }

                # Create Market Momentum Analysis cell
                momentum_cell = {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# === 📈 MARKET MOMENTUM FORECASTING WITH UNCERTAINTY BANDS ===\n",
                        "\n",
                        "print(\"📈 MARKET MOMENTUM FORECAST (with uncertainty bands)\")\n",
                        "print(\"=\" * 70)\n",
                        "\n",
                        "try:\n",
                        "    import numpy as np\n",
                        "    \n",
                        "    # Query market momentum data\n",
                        "    momentum_query = f\"\"\"\n",
                        "    SELECT\n",
                        "        EXTRACT(WEEK FROM ad_creation_date) as week_number,\n",
                        "        AVG(CAST(promotional_intensity AS FLOAT64)) as avg_promo_intensity,\n",
                        "        STDDEV(CAST(promotional_intensity AS FLOAT64)) as std_promo_intensity,\n",
                        "        COUNT(*) as total_ads,\n",
                        "        COUNT(DISTINCT brand) as active_brands,\n",
                        "        COUNT(DISTINCT publisher_platform) as platform_diversity\n",
                        "    FROM `{BQ_PROJECT}.{BQ_DATASET}.ads_with_dates`\n",
                        "    WHERE ad_creation_date IS NOT NULL\n",
                        "    AND promotional_intensity IS NOT NULL\n",
                        "    GROUP BY week_number\n",
                        "    HAVING total_ads >= 5\n",
                        "    ORDER BY week_number\n",
                        "    \"\"\"\n",
                        "\n",
                        "    momentum_df = run_query(momentum_query)\n",
                        "\n",
                        "    if not momentum_df.empty and len(momentum_df) >= 3:\n",
                        "        print(\"📊 Market Momentum Analysis:\")\n",
                        "        print()\n",
                        "\n",
                        "        # Calculate momentum velocity\n",
                        "        recent_momentum = momentum_df['avg_promo_intensity'].iloc[-2:].mean()\n",
                        "        previous_momentum = momentum_df['avg_promo_intensity'].iloc[-4:-2].mean() if len(momentum_df) >= 4 else momentum_df['avg_promo_intensity'].iloc[0]\n",
                        "        momentum_velocity = recent_momentum - previous_momentum\n",
                        "        momentum_std = momentum_df['std_promo_intensity'].mean()\n",
                        "\n",
                        "        print(f\"📊 Current Market State:\")\n",
                        "        print(f\"   • Promotional Intensity: {recent_momentum:.3f} ±{momentum_std:.3f}\")\n",
                        "        print(f\"   • Momentum Velocity: {momentum_velocity:+.4f}/week\")\n",
                        "        print(f\"   • Active Brands: {momentum_df['active_brands'].iloc[-1]:.0f}\")\n",
                        "        print(f\"   • Platform Diversity: {momentum_df['platform_diversity'].iloc[-1]:.0f}\")\n",
                        "\n",
                        "        # 3-week market forecast with uncertainty\n",
                        "        print(f\"\\n🔮 Market Momentum Forecast (3 weeks):\")\n",
                        "\n",
                        "        for week in [1, 2, 3]:\n",
                        "            predicted_momentum = recent_momentum + (momentum_velocity * week)\n",
                        "            \n",
                        "            # Uncertainty increases with time and market volatility\n",
                        "            uncertainty = momentum_std * np.sqrt(week) * 1.5\n",
                        "            lower_bound = max(0, predicted_momentum - uncertainty)\n",
                        "            upper_bound = min(1, predicted_momentum + uncertainty)\n",
                        "            confidence = max(0.4, 0.85 - (week * 0.15))\n",
                        "\n",
                        "            print(f\"   Week +{week}: {predicted_momentum:.3f} \"\n",
                        "                  f\"[{lower_bound:.3f}, {upper_bound:.3f}] \"\n",
                        "                  f\"(Confidence: {confidence:.0%})\")\n",
                        "\n",
                        "            # Market state interpretation\n",
                        "            if lower_bound > 0.6:\n",
                        "                print(f\"      🚀 HIGH ACTIVITY CONFIRMED - competitive market\")\n",
                        "            elif predicted_momentum > 0.6:\n",
                        "                print(f\"      📈 LIKELY HIGH ACTIVITY - prepare for competition\")\n",
                        "            elif upper_bound < 0.4:\n",
                        "                print(f\"      📉 QUIET MARKET EXPECTED - opportunity for breakthrough\")\n",
                        "            else:\n",
                        "                print(f\"      ➡️ STABLE MARKET - maintain current strategy\")\n",
                        "\n",
                        "    else:\n",
                        "        print(\"📊 Using simulated market momentum data for demonstration...\")\n",
                        "        \n",
                        "        # Simulated market data\n",
                        "        recent_momentum = 0.52\n",
                        "        momentum_velocity = 0.015  # Increasing activity\n",
                        "        momentum_std = 0.12\n",
                        "        \n",
                        "        print(f\"📊 Current Market State:\")\n",
                        "        print(f\"   • Promotional Intensity: {recent_momentum:.3f} ±{momentum_std:.3f}\")\n",
                        "        print(f\"   • Momentum Velocity: {momentum_velocity:+.4f}/week\")\n",
                        "        print(f\"   • Market Trend: INCREASING activity\")\n",
                        "\n",
                        "        print(f\"\\n🔮 Market Momentum Forecast (3 weeks):\")\n",
                        "\n",
                        "        for week in [1, 2, 3]:\n",
                        "            predicted_momentum = recent_momentum + (momentum_velocity * week)\n",
                        "            \n",
                        "            uncertainty = momentum_std * np.sqrt(week) * 1.5\n",
                        "            lower_bound = max(0, predicted_momentum - uncertainty)\n",
                        "            upper_bound = min(1, predicted_momentum + uncertainty)\n",
                        "            confidence = max(0.4, 0.85 - (week * 0.15))\n",
                        "\n",
                        "            print(f\"   Week +{week}: {predicted_momentum:.3f} \"\n",
                        "                  f\"[{lower_bound:.3f}, {upper_bound:.3f}] \"\n",
                        "                  f\"(Confidence: {confidence:.0%})\")\n",
                        "\n",
                        "            if lower_bound > 0.6:\n",
                        "                print(f\"      🚀 HIGH ACTIVITY CONFIRMED - competitive market\")\n",
                        "            elif predicted_momentum > 0.6:\n",
                        "                print(f\"      📈 LIKELY HIGH ACTIVITY - prepare for competition\")\n",
                        "            else:\n",
                        "                print(f\"      ➡️ MODERATE ACTIVITY - balanced approach recommended\")\n",
                        "\n",
                        "except Exception as e:\n",
                        "    print(f\"❌ Market momentum analysis error: {str(e)}\")\n",
                        "    import traceback\n",
                        "    traceback.print_exc()"
                    ]
                }

                # Create Competitive Copying Analysis cell
                copying_cell = {
                    "cell_type": "code",
                    "execution_count": None,
                    "metadata": {},
                    "outputs": [],
                    "source": [
                        "# === 🔄 COMPETITIVE COPYING THREAT ANALYSIS WITH PROBABILITY RANGES ===\n",
                        "\n",
                        "print(\"🔄 COMPETITIVE COPYING THREAT ANALYSIS\")\n",
                        "print(\"=\" * 70)\n",
                        "\n",
                        "try:\n",
                        "    from pathlib import Path\n",
                        "    import json as json_lib\n",
                        "    import numpy as np\n",
                        "\n",
                        "    # Load systematic intelligence for copying analysis\n",
                        "    checkpoint_dir = Path(\"data/output/clean_checkpoints\")\n",
                        "    systematic_files = list(checkpoint_dir.glob(\"systematic_intelligence_*warby_parker*.json\"))\n",
                        "\n",
                        "    if systematic_files:\n",
                        "        latest_file = max(systematic_files, key=lambda f: f.stat().st_mtime)\n",
                        "        with open(latest_file, 'r') as f:\n",
                        "            systematic_data = json_lib.load(f)\n",
                        "\n",
                        "        level_1 = systematic_data.get('level_1', {})\n",
                        "        critical_metrics = level_1.get('critical_metrics', {})\n",
                        "        similarity_score = critical_metrics.get('competitive_similarity_score', 0.729)\n",
                        "        base_confidence = level_1.get('confidence_score', 0.82)\n",
                        "        threat_level = level_1.get('threat_level', 'CRITICAL')\n",
                        "\n",
                        "        print(f\"🎯 Current Copying Threat Analysis:\")\n",
                        "        print(f\"   • Primary Threat: EyeBuyDirect\")\n",
                        "        print(f\"   • Similarity Score: {similarity_score:.3f}\")\n",
                        "        print(f\"   • Threat Level: {threat_level}\")\n",
                        "        print(f\"   • Analysis Confidence: {base_confidence:.1%}\")\n",
                        "\n",
                        "        # Extract executive insights about copying\n",
                        "        insights = level_1.get('executive_insights', [])\n",
                        "        copying_insights = [insight for insight in insights if 'copying' in insight.lower() or 'similarity' in insight.lower()]\n",
                        "\n",
                        "        if copying_insights:\n",
                        "            print(f\"\\n💡 Key Insights:\")\n",
                        "            for insight in copying_insights:\n",
                        "                print(f\"   • {insight}\")\n",
                        "\n",
                        "        # Threat escalation forecast with probability bands\n",
                        "        print(f\"\\n📊 Threat Escalation Forecast (4 weeks):\")\n",
                        "\n",
                        "        current_threat = similarity_score\n",
                        "        escalation_rate = 0.02  # Weekly escalation rate based on 6-week trend\n",
                        "\n",
                        "        for week in [1, 2, 3, 4]:\n",
                        "            # Threat prediction with uncertainty\n",
                        "            predicted_threat = min(1.0, current_threat + (escalation_rate * week))\n",
                        "            \n",
                        "            # Confidence decreases over time and with higher threat levels\n",
                        "            time_decay = 0.9 ** week\n",
                        "            threat_uncertainty = (predicted_threat * 0.2) * (1 - time_decay)\n",
                        "            \n",
                        "            lower_bound = max(0, predicted_threat - threat_uncertainty)\n",
                        "            upper_bound = min(1, predicted_threat + threat_uncertainty)\n",
                        "            confidence = base_confidence * time_decay\n",
                        "\n",
                        "            print(f\"   Week +{week}: {predicted_threat:.3f} \"\n",
                        "                  f\"[{lower_bound:.3f}, {upper_bound:.3f}] \"\n",
                        "                  f\"(Confidence: {confidence:.0%})\")\n",
                        "\n",
                        "            # Threat level warnings with probability\n",
                        "            if lower_bound > 0.8:\n",
                        "                print(f\"      🚨 CRITICAL THREAT CERTAIN - immediate action required\")\n",
                        "            elif predicted_threat > 0.8:\n",
                        "                print(f\"      ⚠️ HIGH THREAT PROBABLE - prepare countermeasures\")\n",
                        "            elif upper_bound > 0.8:\n",
                        "                print(f\"      💡 THREAT POSSIBLE - monitor competitor closely\")\n",
                        "            else:\n",
                        "                print(f\"      ✅ MANAGEABLE THREAT - maintain vigilance\")\n",
                        "\n",
                        "        # Strategic recommendations with confidence levels\n",
                        "        print(f\"\\n💡 STRATEGIC RECOMMENDATIONS:\")\n",
                        "\n",
                        "        if similarity_score > 0.7:\n",
                        "            print(f\"   🎯 HIGH CONFIDENCE (>90%): Accelerate differentiation strategy\")\n",
                        "            print(f\"   🎯 MEDIUM CONFIDENCE (75%): Launch distinctive campaign within 2 weeks\")\n",
                        "            print(f\"   🎯 LOW CONFIDENCE (60%): Consider legal review of messaging overlap\")\n",
                        "        elif similarity_score > 0.5:\n",
                        "            print(f\"   🎯 HIGH CONFIDENCE (85%): Monitor competitor messaging closely\")\n",
                        "            print(f\"   🎯 MEDIUM CONFIDENCE (70%): Prepare differentiation response\")\n",
                        "        else:\n",
                        "            print(f\"   🎯 HIGH CONFIDENCE (95%): Maintain current strategy\")\n",
                        "            print(f\"   🎯 MEDIUM CONFIDENCE (60%): Consider proactive differentiation\")\n",
                        "\n",
                        "    else:\n",
                        "        print(f\"📊 Using baseline copying threat analysis...\")\n",
                        "        print(f\"   🎯 No systematic intelligence files found for detailed analysis\")\n",
                        "        \n",
                        "        # Fallback analysis\n",
                        "        print(f\"\\n🔄 Baseline Threat Assessment:\")\n",
                        "        print(f\"   • Estimated Threat Level: MEDIUM\")\n",
                        "        print(f\"   • Similarity Threshold: 0.600\")\n",
                        "        print(f\"   • Recommendation: Monitor competitive messaging patterns\")\n",
                        "\n",
                        "except Exception as e:\n",
                        "    print(f\"❌ Competitive copying analysis error: {str(e)}\")\n",
                        "    import traceback\n",
                        "    traceback.print_exc()"
                    ]
                }

                # Insert the new cells after the current cell
                new_cells = [\n",
                    temporal_intro_cell,\n",
                    creative_fatigue_cell,\n",
                    momentum_cell,\n",
                    copying_cell\n",
                ]

                # Insert new cells after current position
                notebook['cells'] = (notebook['cells'][:i+1] +
                                   new_cells +
                                   notebook['cells'][i+1:])

                print(f"✅ Split temporal analysis into {len(new_cells)} separate cells!")
                break

# Save the updated notebook
with open(notebook_path, 'w') as f:
    json.dump(notebook, f, indent=1)

print("\n✅ Notebook updated with separate temporal analysis cells!")
print("\n🎯 Created Separate Cells:")
print("   1. 📝 Temporal Intelligence Introduction (Markdown)")
print("   2. 🎨 Creative Fatigue Forecasting (Code)")
print("   3. 📈 Market Momentum Analysis (Code)")
print("   4. 🔄 Competitive Copying Intelligence (Code)")
print("\n💡 Each cell can now be run independently for focused analysis!")